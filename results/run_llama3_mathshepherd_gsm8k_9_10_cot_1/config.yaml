algorithm:
  beam_search: false
  beam_temperature: 0.2
  do_sample: true
  n_generate_sample: 1
  name: COT_Reward
  result_type: rank
  task: gsm8k
  value_type: reward
llm:
  context_length: 8192
  dtype: float32
  engine: /root/huggingface/Meta-Llama-3-8B-Instruct/
  name: vllm
  ngpu: 1
  stop: null
  temperature: 0
  top_p: 1
reward_llm:
  context_length: 4096
  dtype: float32
  engine: /root/huggingface/math-shepherd-mistral-7b-prm/
  name: openai_vllm
  ngpu: 1
  stop: null
  temperature: 0
  top_p: 1
run:
  batch_size: 1319
  data_path: /root/huggingface/gsm8k
  log_path: results/run_llama3_mathshepherd_gsm8k_9_10_cot_1
